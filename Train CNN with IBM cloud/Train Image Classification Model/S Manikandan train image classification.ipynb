{"cells": [{"metadata": {}, "cell_type": "code", "source": "!pip install keras-tuner", "execution_count": 46, "outputs": [{"output_type": "stream", "text": "Collecting keras-tuner\n  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 135 kB 25.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras-tuner) (21.3)\nRequirement already satisfied: numpy in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras-tuner) (1.20.3)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras-tuner) (2.26.0)\nRequirement already satisfied: tensorboard in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras-tuner) (2.7.0)\nRequirement already satisfied: ipython in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras-tuner) (7.29.0)\nCollecting kt-legacy\n  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\nRequirement already satisfied: backcall in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython->keras-tuner) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython->keras-tuner) (0.1.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython->keras-tuner) (4.8.0)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython->keras-tuner) (58.0.4)\nRequirement already satisfied: pickleshare in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython->keras-tuner) (0.7.5)\nRequirement already satisfied: pygments in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython->keras-tuner) (2.10.0)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython->keras-tuner) (5.1.1)\nRequirement already satisfied: decorator in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython->keras-tuner) (5.1.0)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython->keras-tuner) (3.0.20)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ipython->keras-tuner) (0.18.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from jedi>=0.16->ipython->keras-tuner) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pexpect>4.3->ipython->keras-tuner) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from packaging->keras-tuner) (3.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->keras-tuner) (1.26.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->keras-tuner) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->keras-tuner) (2022.6.15)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->keras-tuner) (2.0.4)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard->keras-tuner) (0.4.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard->keras-tuner) (3.3.3)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard->keras-tuner) (1.23.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard->keras-tuner) (2.0.2)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard->keras-tuner) (0.6.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard->keras-tuner) (0.12.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard->keras-tuner) (0.37.0)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard->keras-tuner) (3.19.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard->keras-tuner) (1.6.0)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard->keras-tuner) (1.42.0)\nRequirement already satisfied: six in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from absl-py>=0.4->tensorboard->keras-tuner) (1.15.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\nInstalling collected packages: kt-legacy, keras-tuner\nSuccessfully installed keras-tuner-1.1.3 kt-legacy-1.0.4\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 38, "outputs": [{"output_type": "execute_result", "execution_count": 38, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "\n# @hidden_cell\n# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n# You might want to remove those credentials before you share your notebook.\ncredentials_1 = {\n    'IAM_SERVICE_ID': 'iam-ServiceId-0a54def8-ba7a-4324-86c3-91a7d4e0f076',\n    'IBM_API_KEY_ID': 'QCDLqdfd2xk4nas6XFp-lGuleeLyqfOx-uIfCNWkM9Wg',\n    'ENDPOINT': 'https://s3.private.eu.cloud-object-storage.appdomain.cloud',\n    'IBM_AUTH_ENDPOINT': 'https://iam.cloud.ibm.com/oidc/token',\n    'BUCKET': 'forestfiredetection-donotdelete-pr-xhu8yulw9tk7x9',\n    'FILE': '1900.zip'\n}\n", "execution_count": 39, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_botocore.client import Config\nimport ibm_boto3\n\ncos = ibm_boto3.client(service_name='s3',\n                      ibm_api_key_id=credentials_1['IBM_API_KEY_ID'],\n                      ibm_service_instance_id=credentials_1['IAM_SERVICE_ID'],\n                      ibm_auth_endpoint=credentials_1['IBM_AUTH_ENDPOINT'],\n                      config=Config(signature_version='oauth'),\n                      endpoint_url=credentials_1['ENDPOINT'])", "execution_count": 40, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cos.download_file(Bucket=credentials_1['BUCKET'],Key='ffd.zip',Filename='ffd.zip')", "execution_count": 41, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from zipfile import ZipFile\n\nprint('Extract all files in zip to curent directory')\nwith ZipFile('ffd.zip','r') as zipObj:\n    zipObj.extractall()", "execution_count": 70, "outputs": [{"output_type": "stream", "text": "Extract all files in zip to curent directory\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import os\nos.listdir()", "execution_count": 94, "outputs": [{"output_type": "execute_result", "execution_count": 94, "data": {"text/plain": "['ffd.zip', '.virtual_documents', 'content']"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "import shutil\nshutil.rmtree('my_project')", "execution_count": 93, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#To define linear intialisation import Sequential \nfrom keras.models import Sequential\n#To add Layers import Dense\nfrom keras.layers import Dense\n#To create Convolution kernel import convolution2D\nfrom keras.layers import Convolution2D\n#import Maxpooling layer\nfrom keras.layers import MaxPooling2D\n#import Flatten Layer\nfrom keras.layers import Flatten\nfrom keras.models import load_model\n\nimport warnings\nwarnings.filterwarnings('ignore')", "execution_count": 48, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import keras  \nfrom keras.preprocessing.image import ImageDataGenerator\ndef getdata():\n    train_datagen=ImageDataGenerator (rescale=1./255,\n                                        shear_range=0.2,\n                                        rotation_range=180,\n                                        zoom_range=0.2,\n                                        horizontal_flip=True)\n\n    test_datagen=ImageDataGenerator (rescale=1./255)\n\n    test_path = \"content/drive/MyDrive/Forest Fire Dataset/Testing\"\n\n    train_path = \"content/drive/MyDrive/Forest Fire Dataset/Training\"\n\n    x_train = train_datagen.flow_from_directory(train_path, \n                                                target_size = (128,128), \n                                                batch_size = 32, \n                                                class_mode= 'categorical')\n\n    x_test = test_datagen.flow_from_directory(test_path, \n                                                target_size = (128,128), \n                                                batch_size = 32, \n                                                class_mode= 'categorical')\n    return x_train, x_test", "execution_count": 87, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x_train, x_test = getdata()", "execution_count": 88, "outputs": [{"output_type": "stream", "text": "Found 1530 images belonging to 2 classes.\nFound 380 images belonging to 2 classes.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "def build_model(hp):\n    # create model object\n    model = keras.Sequential([\n    #adding first convolutional layer    \n    keras.layers.Conv2D(\n        #adding filter \n        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=2),\n        # adding filter size or kernel size\n        kernel_size=hp.Choice('conv_1_kernel', values = [3,5,7]),\n        #activation function\n        activation='relu',\n        input_shape=(128,128,3)),\n    # adding second convolutional layer \n    keras.layers.Conv2D(\n        #adding filter \n        filters=hp.Int('conv_2_filter', min_value=32, max_value=128, step=2),\n        #adding filter size or kernel size\n        kernel_size=hp.Choice('conv_2_kernel', values = [3,5,7]),\n        #activation function\n        activation='relu'\n    ),\n    # adding flatten layer    \n    keras.layers.Flatten(),\n    # adding dense layer    \n    keras.layers.Dense(\n        units=hp.Int('dense_1_units', min_value=32, max_value=64, step=2),\n        activation='relu'\n    ),\n    # adding dense layer    \n    keras.layers.Dense(\n        units=hp.Int('dense_2_units', min_value=64, max_value=128, step=2),\n        activation='relu'\n    ),\n    # output layer    \n    keras.layers.Dense(2, activation='softmax')\n    ])\n    #compilation of model\n    model.compile(optimizer=keras.optimizers.adam_v2.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n    return model", "execution_count": 90, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from keras.callbacks import EarlyStopping\nes = EarlyStopping(\n    monitor=\"val_loss\",\n    patience=3,\n    restore_best_weights=True)", "execution_count": 91, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from keras_tuner import BayesianOptimization\n#creating Bayesiansearch object\ntuner = BayesianOptimization(build_model,\n                    objective='val_accuracy',\n                    max_trials = 30,\n                    executions_per_trial=1,\n                    overwrite=True,\n                    directory='my_project')\n# search best parameter\ntuner.search(x_train,epochs=3,validation_data=(x_test)) ", "execution_count": 95, "outputs": [{"output_type": "stream", "text": "Trial 3 Complete [00h 17m 52s]\nval_accuracy: 0.9394736886024475\n\nBest val_accuracy So Far: 0.9394736886024475\nTotal elapsed time: 00h 35m 37s\n\nSearch: Running Trial #4\n\nValue             |Best Value So Far |Hyperparameter\n128               |32                |conv_1_filter\n3                 |3                 |conv_1_kernel\n128               |128               |conv_2_filter\n7                 |7                 |conv_2_kernel\n32                |64                |dense_1_units\n64                |64                |dense_2_units\n0.001             |0.001             |learning_rate\n\nEpoch 1/3\n48/48 [==============================] - 1235s 26s/step - loss: 1.4159 - accuracy: 0.8327 - val_loss: 0.2099 - val_accuracy: 0.9342\nEpoch 2/3\n48/48 [==============================] - 1196s 25s/step - loss: 0.1939 - accuracy: 0.9294 - val_loss: 0.1887 - val_accuracy: 0.9421\nEpoch 3/3\n 4/48 [=>............................] - ETA: 17:05 - loss: 0.2552 - accuracy: 0.9219", "name": "stdout"}, {"output_type": "error", "ename": "KeyboardInterrupt", "evalue": "", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_164/501067438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     directory='my_project')\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# search best parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}, {"metadata": {}, "cell_type": "code", "source": "models = tuner.get_best_models(num_models=2)\nbest_model = models[0]\n# Build the model.\n# Needed for `Sequential` without specified `input_shape`.\nbest_model.build(input_shape=(128,128,3))\nbest_model.summary()", "execution_count": 96, "outputs": [{"output_type": "stream", "text": "2022-09-30 15:12:57.758373: W tensorflow/core/framework/op_kernel.cc:1733] INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_11 in the registry.\nTraceback (most recent call last):\n\n  File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 263, in __call__\n    raise ValueError(f\"Could not find callback with key={token} in the \"\n\nValueError: Could not find callback with key=pyfunc_11 in the registry.\n\n\n2022-09-30 15:12:57.758489: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_11 in the registry.\nTraceback (most recent call last):\n\n  File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 263, in __call__\n    raise ValueError(f\"Could not find callback with key={token} in the \"\n\nValueError: Could not find callback with key=pyfunc_11 in the registry.\n\n\n\t [[{{node PyFunc}}]]\n", "name": "stderr"}, {"output_type": "stream", "text": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 126, 126, 32)      896       \n                                                                 \n conv2d_1 (Conv2D)           (None, 120, 120, 128)     200832    \n                                                                 \n flatten (Flatten)           (None, 1843200)           0         \n                                                                 \n dense (Dense)               (None, 64)                117964864 \n                                                                 \n dense_1 (Dense)             (None, 64)                4160      \n                                                                 \n dense_2 (Dense)             (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 118,170,882\nTrainable params: 118,170,882\nNon-trainable params: 0\n_________________________________________________________________\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from keras import callbacks\n#Training the model \nhistory = best_model.fit_generator(x_train, steps_per_epoch=len(x_train), \n                    epochs=30, validation_data=x_test,\n                    callbacks = [es],\n                    validation_steps=len(x_test))\n\n#save the model\nbest_model.save(\"forest1.h5\")", "execution_count": null, "outputs": [{"output_type": "stream", "text": "Epoch 1/30\n48/48 [==============================] - 361s 7s/step - loss: 0.2067 - accuracy: 0.9255 - val_loss: 0.2085 - val_accuracy: 0.9342\nEpoch 2/30\n48/48 [==============================] - 361s 8s/step - loss: 0.1941 - accuracy: 0.9399 - val_loss: 0.1711 - val_accuracy: 0.9526\nEpoch 3/30\n 1/48 [..............................] - ETA: 5:52 - loss: 0.0526 - accuracy: 1.0000", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\nfrom tensorflow.keras.preprocessing import image\nimg = image.load_img('content/drive/MyDrive/Forest Fire Dataset/Testing.jpg',target_size=(128,128))\nimg", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x = image.img_to_array(img)\nx = np.expand_dims(x,axis=0)\nx", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "best_model.predict(x)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "xtrain.class_indices", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "op = ['','']\npred = np.argmax(model.predict(x))\nop[pred]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nprint(\"Accuracy of our model on test data : \" , best_model.evaluate(x_test)[1]*100 , \"%\")\n\nepochs = [i for i in range(50)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\ntest_acc = history.history['val_accuracy']\ntest_loss = history.history['val_loss']\n\n\nax[0].plot(epochs , train_loss , label = 'Training Loss')\nax[0].plot(epochs , test_loss , label = 'Testing Loss')\nax[0].set_title('Training & Testing Loss')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\n\nax[1].plot(epochs , train_acc , label = 'Training Accuracy')\nax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\nax[1].set_title('Training & Testing Accuracy')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nplt.show()", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}